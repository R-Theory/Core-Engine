"""Initial migration

Revision ID: 12bc49ecc659
Revises: 
Create Date: 2025-09-18 22:01:20.077350

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '12bc49ecc659'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('resources', sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.drop_column('resources', 'meta')
    op.add_column('user_context_documents', sa.Column('ai_context_id', sa.UUID(), nullable=False))
    op.add_column('user_context_documents', sa.Column('file_type', sa.String(length=50), nullable=False))
    op.add_column('user_context_documents', sa.Column('content', sa.Text(), nullable=True))
    op.add_column('user_context_documents', sa.Column('summary', sa.Text(), nullable=True))
    op.add_column('user_context_documents', sa.Column('key_points', sa.JSON(), nullable=True))
    op.add_column('user_context_documents', sa.Column('embeddings', sa.JSON(), nullable=True))
    op.add_column('user_context_documents', sa.Column('document_type', sa.String(length=50), nullable=True))
    op.add_column('user_context_documents', sa.Column('relevance_score', sa.Integer(), nullable=True))
    op.add_column('user_context_documents', sa.Column('tags', sa.JSON(), nullable=True))
    op.add_column('user_context_documents', sa.Column('processing_status', sa.String(length=20), nullable=True))
    op.add_column('user_context_documents', sa.Column('storage_path', sa.String(length=500), nullable=True))
    op.add_column('user_context_documents', sa.Column('storage_metadata', sa.JSON(), nullable=True))
    op.add_column('user_context_documents', sa.Column('uploaded_at', sa.DateTime(), nullable=True))
    op.add_column('user_context_documents', sa.Column('processed_at', sa.DateTime(), nullable=True))
    op.add_column('user_context_documents', sa.Column('last_accessed', sa.DateTime(), nullable=True))
    # Convert file_size column from VARCHAR to INTEGER with proper type conversion
    op.execute("ALTER TABLE user_context_documents ALTER COLUMN file_size TYPE INTEGER USING CASE WHEN file_size ~ '^[0-9]+$' THEN file_size::integer ELSE 0 END")
    op.drop_constraint('user_context_documents_profile_id_fkey', 'user_context_documents', type_='foreignkey')
    op.create_foreign_key(None, 'user_context_documents', 'user_ai_contexts', ['ai_context_id'], ['id'])
    op.drop_column('user_context_documents', 'extracted_text')
    op.drop_column('user_context_documents', 'file_path')
    op.drop_column('user_context_documents', 'is_processed')
    op.drop_column('user_context_documents', 'mime_type')
    op.drop_column('user_context_documents', 'updated_at')
    op.drop_column('user_context_documents', 'profile_id')
    op.drop_column('user_context_documents', 'created_at')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('user_context_documents', sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('user_context_documents', sa.Column('profile_id', sa.UUID(), autoincrement=False, nullable=False))
    op.add_column('user_context_documents', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('user_context_documents', sa.Column('mime_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('user_context_documents', sa.Column('is_processed', sa.BOOLEAN(), autoincrement=False, nullable=True))
    op.add_column('user_context_documents', sa.Column('file_path', sa.VARCHAR(length=500), autoincrement=False, nullable=False))
    op.add_column('user_context_documents', sa.Column('extracted_text', sa.TEXT(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'user_context_documents', type_='foreignkey')
    op.create_foreign_key('user_context_documents_profile_id_fkey', 'user_context_documents', 'user_profiles', ['profile_id'], ['id'])
    # Convert file_size column back from INTEGER to VARCHAR
    op.execute("ALTER TABLE user_context_documents ALTER COLUMN file_size TYPE VARCHAR(50) USING file_size::text")
    op.drop_column('user_context_documents', 'last_accessed')
    op.drop_column('user_context_documents', 'processed_at')
    op.drop_column('user_context_documents', 'uploaded_at')
    op.drop_column('user_context_documents', 'storage_metadata')
    op.drop_column('user_context_documents', 'storage_path')
    op.drop_column('user_context_documents', 'processing_status')
    op.drop_column('user_context_documents', 'tags')
    op.drop_column('user_context_documents', 'relevance_score')
    op.drop_column('user_context_documents', 'document_type')
    op.drop_column('user_context_documents', 'embeddings')
    op.drop_column('user_context_documents', 'key_points')
    op.drop_column('user_context_documents', 'summary')
    op.drop_column('user_context_documents', 'content')
    op.drop_column('user_context_documents', 'file_type')
    op.drop_column('user_context_documents', 'ai_context_id')
    op.add_column('resources', sa.Column('meta', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_column('resources', 'metadata')
    # ### end Alembic commands ###
